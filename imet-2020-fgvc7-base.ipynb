{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-waterproof",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q loguru\n",
    "!pip install -q mlcrate\n",
    "!pip install -q omegaconf\n",
    "!pip install -q segmentation_models\n",
    "!pip install -q iterative-stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-stack",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from collections import OrderedDict\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from loguru import logger\n",
    "import mlcrate as mlc\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-ability",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'expr_name': 'expr007',\n",
    "    'save_root': './',\n",
    "    \n",
    "    'data_root': '../input/imet-2020-fgvc7/',\n",
    "    \n",
    "    'device': {\n",
    "        'name': 'gpu',\n",
    "        'id': '0'\n",
    "    },\n",
    "    \n",
    "    'num_epochs': 28,\n",
    "    'batch_size': 32,\n",
    "    'run_fold1_only': True,\n",
    "    \n",
    "    'scheduler': {\n",
    "        'name': 'CosineScheduler',\n",
    "        'params': {\n",
    "            'init_lr': 1e-3,\n",
    "            'min_lr': 1e-5,\n",
    "            'total_epochs': 20,\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    #\n",
    "    \n",
    "    'transform': {\n",
    "        'val_size': (320, 320),\n",
    "        'train_size': (320, 320),\n",
    "        'aug_name': 'rand_augment',\n",
    "        'aug_params': {\n",
    "            'num_augments': 2,\n",
    "            'magnitude': 5,\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    'model': {\n",
    "        'base_func': \"cs.Classifiers.get('resnet34')[0]\",\n",
    "        'base_weights': 'imagenet',\n",
    "        'dropout_rate': 0.1,\n",
    "    },\n",
    "    \n",
    "    'stages': {\n",
    "        'epochs': [0, 6, 14, 20],\n",
    "        'transforms': [\n",
    "            {'train_size': (224, 224), 'aug_params': {'num_augments':2, 'magnitude': 2}},\n",
    "            {'train_size': (256, 256), 'aug_params': {'num_augments':2, 'magnitude': 3}},\n",
    "            {'train_size': (288, 288), 'aug_params': {'num_augments':2, 'magnitude': 4}},\n",
    "            {'train_size': (320, 320), 'aug_params': {'num_augments':2, 'magnitude': 5}},\n",
    "        ],\n",
    "        'models': [\n",
    "            {'dropout_rate': 0.0},\n",
    "            {'dropout_rate': 0.0},\n",
    "            {'dropout_rate': 0.1},\n",
    "            {'dropout_rate': 0.2},\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    #\n",
    "    \n",
    "    'loss': {\n",
    "        'name': 'tf.keras.losses.BinaryCrossentropy',\n",
    "        'params': {'reduction': 'none'},\n",
    "        'weight_decay': 1e-5,\n",
    "    },\n",
    "    \n",
    "    'optimizer': {\n",
    "        'name': 'tf.keras.optimizers.Adam',\n",
    "        'params': {}\n",
    "    },\n",
    "    \n",
    "    'seed': 8888,\n",
    "    'num_classes': 3474,\n",
    "    'num_folds': 5,\n",
    "}\n",
    "\n",
    "config = OmegaConf.create(config)\n",
    "OmegaConf.update(config, 'save_path', os.path.join(config.save_root, config.expr_name), merge=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-jonathan",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.device.name == 'gpu':\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = config.device.id\n",
    "elif config.device.name == 'cpu':\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-alexander",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import classification_models.tfkeras as cs\n",
    "import efficientnet.tfkeras as eff\n",
    "\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "seed_everything(config.seed)\n",
    "\n",
    "\n",
    "if config.device.name == 'tpu':\n",
    "    from kaggle_datasets import KaggleDatasets\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "OmegaConf.update(config, 'batch_size', config.batch_size * strategy.num_replicas_in_sync, merge=True)\n",
    "OmegaConf.update(config, 'scheduler.params.init_lr', config.scheduler.params.init_lr * strategy.num_replicas_in_sync, merge=True)\n",
    "OmegaConf.update(config, 'scheduler.params.min_lr', config.scheduler.params.min_lr * strategy.num_replicas_in_sync, merge=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-wallace",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Train/Val List - CUSTOM\n",
    "'''\n",
    "\n",
    "df = pd.read_csv(os.path.join(config.data_root, 'train.csv'))\n",
    "fpath_list = np.array(os.path.join(config.data_root, 'train-320/') + df.id + '.jpg')\n",
    "label_list = np.load(os.path.join(config.data_root, 'labels.npy'))\n",
    "fold_assignments = np.load(os.path.join(config.data_root, f'fold-assignment_K-{config.num_folds}_seed-{config.seed}.npy'))\n",
    "\n",
    "\n",
    "def get_train_val_list(fold_idx):\n",
    "    train_fpaths = fpath_list[fold_assignments!=fold_idx]\n",
    "    val_fpaths = fpath_list[fold_assignments==fold_idx]\n",
    "\n",
    "    train_labels = label_list[fold_assignments!=fold_idx]\n",
    "    val_labels = label_list[fold_assignments==fold_idx]\n",
    "    \n",
    "    return (train_fpaths, train_labels), (val_fpaths, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-pressure",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Transform\n",
    "'''\n",
    "def load_image(fine_size, aug_func):\n",
    "    @tf.function\n",
    "    def load_image_(fpath, label):\n",
    "        img = tf.image.decode_jpeg(tf.io.read_file(fpath))\n",
    "        img = tf.cast(tf.image.resize(img, fine_size), tf.uint8)\n",
    "        img = tf.ensure_shape(img, fine_size + (3,))\n",
    "        \n",
    "        if aug_func is not None:\n",
    "            img = aug_func(img)\n",
    "            \n",
    "        img = tf.cast(img, tf.float32) / 255.\n",
    "        return img, label\n",
    "    return load_image_\n",
    "\n",
    "def augment():\n",
    "    @tf.function\n",
    "    def augment_(img):\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "        img = tf.image.random_contrast(img, 0.6, 1.2)\n",
    "        img = tf.image.random_saturation(img, 0.6, 1.2)\n",
    "        img = tf.image.random_brightness(img, 0.2)\n",
    "        return img\n",
    "    return augment_\n",
    "\n",
    "def rand_augment(num_augments, magnitude):\n",
    "    ra = RandAugment()\n",
    "    @tf.function\n",
    "    def rand_augment_(img):\n",
    "        ra.apply(img, num_augments=num_augments, magnitude=magnitude)\n",
    "        return img\n",
    "    return rand_augment_\n",
    "\n",
    "'''\n",
    "Rand Augment\n",
    "'''\n",
    "class RandAugment:\n",
    "    def __init__(self, max_level=10, cutout_const=80, translate_const=100, replace_value=0):\n",
    "        self.max_level = max_level\n",
    "        self.cutout_const = cutout_const\n",
    "        self.translate_const = translate_const\n",
    "        self.replace = replace_value\n",
    "        self.operations = [\n",
    "            self.identity,\n",
    "            self.autocontrast,\n",
    "            self.equalize,\n",
    "            self.invert,\n",
    "            self.rotate,\n",
    "            self.posterize,\n",
    "            self.solarize,\n",
    "            self.solarize_add,\n",
    "            self.color,\n",
    "            self.contrast,\n",
    "            self.brightness,\n",
    "            self.sharpness,\n",
    "            self.shear_x,\n",
    "            self.shear_y,\n",
    "            self.translate_x,\n",
    "            self.translate_y,\n",
    "            self.cutout,\n",
    "        ]\n",
    "        \n",
    "    @tf.function\n",
    "    def apply(self, uint8_image, num_augments=2, magnitude=5, constant=True):\n",
    "        for _ in range(num_augments):\n",
    "            op_to_select = tf.random.uniform((), 0, len(self.operations), dtype=tf.int32)\n",
    "            if constant:\n",
    "                level = tf.cast(magnitude, tf.float32)\n",
    "            else:\n",
    "                level = tf.random.uniform((), 0., tf.cast(magnitude, tf.float32), dtype=tf.float32)\n",
    "            for i, operation in enumerate(self.operations):\n",
    "                uint8_image = tf.cond(\n",
    "                    tf.equal(i, op_to_select),\n",
    "                    lambda: operation(uint8_image, level),\n",
    "                    lambda: uint8_image\n",
    "                )\n",
    "        return uint8_image\n",
    "    \n",
    "    @tf.function\n",
    "    def _rotate_level_to_arg(self, rel_level):\n",
    "        level = rel_level * 30.\n",
    "        level = level if tf.random.normal(()) > 0. else -level\n",
    "        return level\n",
    "    \n",
    "    @tf.function\n",
    "    def _enhance_level_to_arg(self, rel_level):\n",
    "        return rel_level * 1.8 + 0.1\n",
    "    \n",
    "    @tf.function\n",
    "    def _shear_level_to_arg(self, rel_level):\n",
    "        level = rel_level * 0.3\n",
    "        level = level if tf.random.normal(()) > 0. else -level\n",
    "        return level\n",
    "    \n",
    "    @tf.function\n",
    "    def _translate_level_to_arg(self, rel_level, translate_const):\n",
    "        level = rel_level * tf.cast(translate_const, tf.float32)\n",
    "        level = level if tf.random.normal(()) > 0. else -level\n",
    "        return level\n",
    "    \n",
    "    # -------------------------------------------------------------------------------------\n",
    "    \n",
    "    @tf.function\n",
    "    def identity(self, image, level):\n",
    "        return image\n",
    "    \n",
    "    @tf.function\n",
    "    def autocontrast(self, image, level):\n",
    "        @tf.function\n",
    "        def scale_channel(image):\n",
    "            \"\"\"Scale the 2D image using the autocontrast rule.\"\"\"\n",
    "            # A possibly cheaper version can be done using cumsum/unique_with_counts\n",
    "            # over the histogram values, rather than iterating over the entire image.\n",
    "            # to compute mins and maxes.\n",
    "            lo = tf.cast(tf.reduce_min(image), tf.float32)\n",
    "            hi = tf.cast(tf.reduce_max(image), tf.float32)\n",
    "            # Scale the image, making the lowest value 0 and the highest value 255.\n",
    "            def scale_values(im):\n",
    "                scale = 255.0 / (hi - lo)\n",
    "                offset = -lo * scale\n",
    "                im = tf.cast(im, tf.float32) * scale + offset\n",
    "                im = tf.clip_by_value(im, 0.0, 255.0)\n",
    "                return tf.cast(im, tf.uint8)\n",
    "            result = tf.cond(hi > lo, lambda: scale_values(image), lambda: image)\n",
    "            return result\n",
    "        s1 = scale_channel(image[:, :, 0])\n",
    "        s2 = scale_channel(image[:, :, 1])\n",
    "        s3 = scale_channel(image[:, :, 2])\n",
    "        image = tf.stack([s1, s2, s3], axis=-1)\n",
    "        return image\n",
    "    \n",
    "    @tf.function\n",
    "    def equalize(self, image, level):\n",
    "        return tfa.image.equalize(image)\n",
    "    \n",
    "    @tf.function\n",
    "    def invert(self, image, level):\n",
    "        return tf.bitwise.invert(image)\n",
    "    \n",
    "    @tf.function\n",
    "    def rotate(self, image, level):\n",
    "        degree = self._rotate_level_to_arg(level/self.max_level)\n",
    "        radian = degree * math.pi / 180.0\n",
    "        return tfa.image.rotate(image, radian)\n",
    "    \n",
    "    @tf.function\n",
    "    def posterize(self, image, level):\n",
    "        bits = tf.cast((level/self.max_level) * 4, tf.uint8)\n",
    "        shift = 8 - bits\n",
    "        return tf.bitwise.left_shift(tf.bitwise.right_shift(image, shift), shift)\n",
    "    \n",
    "    @tf.function\n",
    "    def solarize(self, image, level):\n",
    "        threshold = tf.cast((level/self.max_level) * 256, tf.uint8)\n",
    "        return tf.where(image < threshold, image, 255 - image)\n",
    "    \n",
    "    @tf.function\n",
    "    def solarize_add(self, image, level):\n",
    "        addition = tf.cast((level/self.max_level) * 110, tf.int64)\n",
    "        added_image = tf.cast(image, tf.int64) + addition\n",
    "        added_image = tf.cast(tf.clip_by_value(added_image, 0, 255), tf.uint8)\n",
    "        return tf.where(image < 128, added_image, image)\n",
    "    \n",
    "    @tf.function\n",
    "    def color(self, image, level):\n",
    "        factor = self._enhance_level_to_arg(level/self.max_level)\n",
    "        degenerate = tf.image.grayscale_to_rgb(tf.image.rgb_to_grayscale(image))\n",
    "        return tf.cast(tfa.image.blend(tf.cast(degenerate, tf.float32), tf.cast(image, tf.float32), factor), tf.uint8)\n",
    "    \n",
    "    @tf.function\n",
    "    def contrast(self, image, level):\n",
    "        factor = self._enhance_level_to_arg(level/self.max_level)\n",
    "        \"\"\"Equivalent of PIL Contrast.\"\"\"\n",
    "        degenerate = tf.image.rgb_to_grayscale(image)\n",
    "        # Cast before calling tf.histogram.\n",
    "        degenerate = tf.cast(degenerate, tf.int32)\n",
    "        # Compute the grayscale histogram, then compute the mean pixel value,\n",
    "        # and create a constant image size of that value.  Use that as the\n",
    "        # blending degenerate target of the original image.\n",
    "        hist = tf.histogram_fixed_width(degenerate, [0, 255], nbins=256)\n",
    "        mean = tf.reduce_sum(tf.cast(hist, tf.float32)) / 256.0\n",
    "        degenerate = tf.ones_like(degenerate, dtype=tf.float32) * mean\n",
    "        degenerate = tf.clip_by_value(degenerate, 0.0, 255.0)\n",
    "        degenerate = tf.image.grayscale_to_rgb(tf.cast(degenerate, tf.uint8))\n",
    "        return tf.cast(tfa.image.blend(tf.cast(degenerate, tf.float32), tf.cast(image, tf.float32), factor), tf.uint8)\n",
    "    \n",
    "    @tf.function\n",
    "    def brightness(self, image, level):\n",
    "        factor = self._enhance_level_to_arg(level/self.max_level)\n",
    "        degenerate = tf.zeros_like(image)\n",
    "        return tf.cast(tfa.image.blend(tf.cast(degenerate, tf.float32), tf.cast(image, tf.float32), factor), tf.uint8)\n",
    "    \n",
    "    @tf.function\n",
    "    def sharpness(self, image, level):\n",
    "        factor = self._enhance_level_to_arg(level/self.max_level)\n",
    "        \"\"\"Implements Sharpness function from PIL using TF ops.\"\"\"\n",
    "        orig_image = image\n",
    "        image = tf.cast(image, tf.float32)\n",
    "        # Make image 4D for conv operation.\n",
    "        image = tf.expand_dims(image, 0)\n",
    "        # SMOOTH PIL Kernel.\n",
    "        kernel = tf.constant(\n",
    "          [[1, 1, 1], [1, 5, 1], [1, 1, 1]], dtype=tf.float32,\n",
    "          shape=[3, 3, 1, 1]\n",
    "        ) / 13.\n",
    "        # Tile across channel dimension.\n",
    "        kernel = tf.tile(kernel, [1, 1, 3, 1])\n",
    "        strides = [1, 1, 1, 1]\n",
    "        with tf.device('/cpu:0'):\n",
    "            # Some augmentation that uses depth-wise conv will cause crashing when\n",
    "            # training on GPU. See (b/156242594) for details.\n",
    "            degenerate = tf.nn.depthwise_conv2d(\n",
    "                image, kernel, strides, padding='VALID', dilations=[1, 1]\n",
    "            )\n",
    "        degenerate = tf.clip_by_value(degenerate, 0.0, 255.0)\n",
    "        degenerate = tf.squeeze(tf.cast(degenerate, tf.uint8), [0])\n",
    "        # For the borders of the resulting image, fill in the values of the\n",
    "        # original image.\n",
    "        mask = tf.ones_like(degenerate)\n",
    "        padded_mask = tf.pad(mask, [[1, 1], [1, 1], [0, 0]])\n",
    "        padded_degenerate = tf.pad(degenerate, [[1, 1], [1, 1], [0, 0]])\n",
    "        result = tf.where(tf.equal(padded_mask, 1), padded_degenerate, orig_image)\n",
    "        # Blend the final result.\n",
    "        return tf.cast(tfa.image.blend(tf.cast(result, tf.float32), tf.cast(orig_image, tf.float32), factor), tf.uint8)\n",
    "    \n",
    "    @tf.function\n",
    "    def shear_x(self, image, level):\n",
    "        level = self._shear_level_to_arg(level/self.max_level)\n",
    "        return tfa.image.shear_x(image, level, self.replace)\n",
    "    \n",
    "    @tf.function\n",
    "    def shear_y(self, image, level):\n",
    "        level = self._shear_level_to_arg(level/self.max_level)\n",
    "        return tfa.image.shear_y(image, level, self.replace)\n",
    "    \n",
    "    @tf.function\n",
    "    def cutout(self, image, level):\n",
    "        mask_size = int((level/self.max_level) * self.cutout_const)\n",
    "        return tfa.image.random_cutout(tf.expand_dims(image, 0), mask_size, self.replace)[0]\n",
    "    \n",
    "    @tf.function\n",
    "    def translate_x(self, image, level):\n",
    "        pixels = self._translate_level_to_arg(level/self.max_level, self.translate_const)\n",
    "        return tfa.image.translate_xy(image, [-pixels, 0], self.replace)\n",
    "    \n",
    "    @tf.function\n",
    "    def translate_y(self, image, level):\n",
    "        pixels = self._translate_level_to_arg(level/self.max_level, self.translate_const)\n",
    "        return tfa.image.translate_xy(image, [0, -pixels], self.replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-interval",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DataLoader\n",
    "'''\n",
    "def get_ds(train_data, val_data, batch_size, train_size, val_size, aug_func):\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        train_data\n",
    "    ).shuffle(\n",
    "        len(train_data[0])\n",
    "    ).map(\n",
    "        load_image(train_size, aug_func), num_parallel_calls=tf.data.AUTOTUNE, deterministic=False\n",
    "    ).batch(\n",
    "        batch_size, drop_remainder=True\n",
    "    ).repeat(-1).prefetch(1)\n",
    "\n",
    "    val_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        val_data\n",
    "    ).map(\n",
    "        load_image(val_size, None), num_parallel_calls=tf.data.AUTOTUNE, deterministic=True\n",
    "    ).batch(\n",
    "        batch_size, drop_remainder=False\n",
    "    ).prefetch(1)\n",
    "    \n",
    "    return train_ds, val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-change",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model - CUSTOM\n",
    "'''\n",
    "def build_model(input_shape, num_classes, dropout_rate, weight_decay, base_func, base_weights):\n",
    "    import os, tempfile\n",
    "    def add_regularization(model, weight_reg):\n",
    "        custom_objects={}\n",
    "        for layer in model.layers:\n",
    "            for attr in ['kernel_regularizer']:\n",
    "                if hasattr(layer, attr):\n",
    "                    setattr(layer, attr, tf.keras.regularizers.l2(weight_reg))\n",
    "        model_json = model.to_json()\n",
    "        tmp_weights_path = os.path.join(tempfile.gettempdir(), 'tmp_weights.h5')\n",
    "        model.save_weights(tmp_weights_path)\n",
    "        model = tf.keras.models.model_from_json(model_json, custom_objects=custom_objects)\n",
    "        model.load_weights(tmp_weights_path, by_name=True)\n",
    "        return model    \n",
    "    \n",
    "    base_model = base_func(input_shape=input_shape, include_top=False, weights=base_weights)\n",
    "    \n",
    "    ip = tf.keras.layers.Input(input_shape)\n",
    "    h = base_model(ip)\n",
    "    h = tf.keras.layers.GlobalAveragePooling2D()(h)\n",
    "    h = tf.keras.layers.Dropout(dropout_rate)(h)\n",
    "    h = tf.keras.layers.Dense(num_classes, activation=tf.nn.sigmoid)(h)\n",
    "    model = tf.keras.models.Model(ip, h)\n",
    "    \n",
    "    if weight_decay > 0.:\n",
    "        model = add_regularization(model, weight_decay)\n",
    "    return model\n",
    "\n",
    "\n",
    "def model_regularizer_loss(model):\n",
    "    loss = 0\n",
    "    for l in model.layers:\n",
    "        if hasattr(l,'layers') and l.layers:\n",
    "            loss += model_regularizer_loss(l)\n",
    "        if hasattr(l,'kernel_regularizer') and l.kernel_regularizer:\n",
    "            loss += l.kernel_regularizer(l.kernel)\n",
    "        if hasattr(l,'bias_regularizer') and l.bias_regularizer:\n",
    "            loss += l.bias_regularizer(l.bias)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-flour",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Metrics - CUSTOM\n",
    "'''\n",
    "class Metrics: # Sample Averaging F2-Score\n",
    "    def __init__(self, threshold=0.2):\n",
    "        self.scores = [tf.keras.metrics.Mean()]\n",
    "        self.threshold = threshold\n",
    "        \n",
    "        self.loss = tf.keras.metrics.Mean()\n",
    "        self.header = ['loss'] + [f'score_{i+1}' for i in range(len(self.scores))]\n",
    "        self.df = pd.DataFrame(columns=self.header)\n",
    "    \n",
    "    def update_state(self, y_trues, y_preds, loss):\n",
    "        trues = y_trues > self.threshold\n",
    "        preds = y_preds > self.threshold\n",
    "        \n",
    "        tps = tf.reduce_sum(tf.cast(trues & (trues & preds), tf.float32), axis=1)\n",
    "        sum_trues = tf.reduce_sum(tf.cast(trues, tf.float32), axis=1)\n",
    "        sum_preds = tf.reduce_sum(tf.cast(preds, tf.float32), axis=1)\n",
    "        \n",
    "        recalls = tf.where(sum_trues > 0., tps / sum_trues, 0.)\n",
    "        precisions = tf.where(sum_preds > 0., tps / sum_preds, 0.)\n",
    "        \n",
    "        denom = 4. * precisions + recalls\n",
    "        denom = tf.where(denom > 0., denom, 1.)\n",
    "        f2_scores = ((1. + 4.) * precisions * recalls) / denom\n",
    "        \n",
    "        self.scores[0].update_state(f2_scores)\n",
    "        self.loss.update_state(loss)\n",
    "    \n",
    "    def get_loss(self):\n",
    "        return self.loss.result().numpy()\n",
    "    \n",
    "    def get_scores(self):\n",
    "        score = self.scores[0].result().numpy()\n",
    "        return [score]\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.scores[0].reset_states()\n",
    "        self.loss.reset_states()\n",
    "    \n",
    "    def on_epoch_end(self, e):\n",
    "        self.df.loc[e] = [self.get_loss()] + self.get_scores()\n",
    "    \n",
    "    def get_latest(self):\n",
    "        return self.df.index.tolist()[-1], self.df.iloc[-1, :].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-orleans",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Scheduler\n",
    "'''\n",
    "\n",
    "class CosineScheduler:\n",
    "    def __init__(self, init_lr, min_lr, total_epochs):\n",
    "        self.curr_lr = init_lr\n",
    "        self.init_lr = init_lr\n",
    "        self.min_lr = min_lr\n",
    "        self.total_epochs = total_epochs\n",
    "    \n",
    "    def get_next_lr(self, next_epoch, curr_loss, curr_score):\n",
    "        self.curr_lr = (self.init_lr - self.min_lr) * 0.5 * (np.cos(np.pi * next_epoch / self.total_epochs) + 1.) + self.min_lr\n",
    "        return self.curr_lr\n",
    "\n",
    "    \n",
    "class ReduceOnPlateauScheduler:\n",
    "    def __init__(self, init_lr, min_lr, decay, max_patience):\n",
    "        self.curr_lr = init_lr\n",
    "        self.min_lr = min_lr\n",
    "        self.decay = decay\n",
    "        self.max_patience = max_patience\n",
    "        self.patience = 0\n",
    "        self.best_loss = 10000.\n",
    "        self.best_score = 0.\n",
    "        \n",
    "    def get_next_lr(self, next_epoch, curr_loss, curr_score):\n",
    "        self.patience += 1\n",
    "        \n",
    "        if curr_loss < self.best_loss:\n",
    "            self.best_loss = curr_loss\n",
    "            self.patience = 0\n",
    "            \n",
    "        if curr_score > self.best_score:\n",
    "            self.best_score = curr_score\n",
    "            self.patience = 0\n",
    "        \n",
    "        if self.patience > self.max_patience:\n",
    "            self.patience = 0\n",
    "            self.curr_lr = max(self.curr_lr * self.decay, self.min_lr)\n",
    "        \n",
    "        return self.curr_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-style",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Train/Val Proc on epoch\n",
    "'''\n",
    "\n",
    "def get_proc_on_batch():\n",
    "    @tf.function\n",
    "    def train_on_batch(inputs, model, criterion, optimizer):\n",
    "        x, y = inputs\n",
    "        with tf.GradientTape() as tape:\n",
    "            p = model(x, training=True)\n",
    "            loss = criterion(y, p)\n",
    "            total_loss = tf.reduce_mean(loss) + model_regularizer_loss(model)\n",
    "        grads = tape.gradient(loss, sources=model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        return y, p, loss\n",
    "\n",
    "    @tf.function\n",
    "    def val_on_batch(inputs, model, criterion):\n",
    "        x, y = inputs\n",
    "        p = model(x, training=False)\n",
    "        loss = criterion(y, p)\n",
    "        return y, p, loss\n",
    "    \n",
    "    return train_on_batch, val_on_batch\n",
    "\n",
    "\n",
    "def proc_on_epoch(training, proc_on_batch, dataset, metrics, criterion, model, epoch, total_epoch, iters_per_epoch=None, optimizer=None):\n",
    "    \n",
    "    metrics.reset_state()\n",
    "    if training:\n",
    "        assert iters_per_epoch is not None\n",
    "        assert optimizer is not None\n",
    "        phase = 'train'\n",
    "    else:\n",
    "        phase = 'valid'\n",
    "    \n",
    "    with tqdm.tqdm(dataset, total=iters_per_epoch, ncols=0, desc=f'{phase} {(1+epoch)}/{total_epoch}') as tq:\n",
    "        for iter_i, inputs in enumerate(tq):\n",
    "            with tf.device('/gpu:0'):\n",
    "                if training:\n",
    "                    if iter_i > iters_per_epoch:\n",
    "                        break\n",
    "                    y, p, loss = proc_on_batch(inputs, model, criterion, optimizer)\n",
    "                else:\n",
    "                    y, p, loss = proc_on_batch(inputs, model, criterion)\n",
    "            \n",
    "            metrics.update_state(y, p, loss)\n",
    "            tq.set_postfix(OrderedDict(\n",
    "                loss = metrics.get_loss(),\n",
    "                scores = metrics.get_scores()\n",
    "            ))\n",
    "    \n",
    "    metrics.on_epoch_end(epoch+1)\n",
    "    if training:\n",
    "        return metrics, model, optimizer\n",
    "    else:\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-campus",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-powell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fold(fold_idx, config):\n",
    "    \n",
    "    scheduler = eval(config.scheduler.name)(**config.scheduler.params)\n",
    "    optimizer = eval(config.optimizer.name)(**config.optimizer.params)\n",
    "    criterion = eval(config.loss.name)(**config.loss.params)\n",
    "\n",
    "    (train_fpaths, train_labels), (val_fpaths, val_labels) = get_train_val_list(fold_idx)\n",
    "    train_iters_per_epoch = len(train_fpaths) // config.batch_size\n",
    "\n",
    "    train_metrics = Metrics()\n",
    "    val_metrics = Metrics()\n",
    "\n",
    "    best_score = 0.\n",
    "    best_loss = 10000.\n",
    "\n",
    "    for e in range(config.num_epochs):\n",
    "\n",
    "        if e in config.stages.epochs:\n",
    "            '''\n",
    "            stage setting: dataset, inference_method, train/val_model\n",
    "            '''\n",
    "            stage_idx = config.stages.epochs.index(e)\n",
    "            config.transform = OmegaConf.merge(config.transform, config.stages.transforms[stage_idx])\n",
    "            config.model = OmegaConf.merge(config.model, config.stages.models[stage_idx])\n",
    "            logger.info(f'New Stage {stage_idx}')\n",
    "\n",
    "            train_ds, val_ds = get_ds(\n",
    "                (train_fpaths, train_labels), (val_fpaths, val_labels), config.batch_size, \n",
    "                tuple(config.transform.train_size), tuple(config.transform.val_size),\n",
    "                eval(config.transform.aug_name)(**config.transform.aug_params),\n",
    "            )\n",
    "            train_on_batch, val_on_batch = get_proc_on_batch()\n",
    "\n",
    "            with strategy.scope():\n",
    "                train_model = build_model(\n",
    "                    tuple(config.transform.train_size) + (3,), config.num_classes, weight_decay=config.loss.weight_decay,\n",
    "                    dropout_rate=config.model.dropout_rate, \n",
    "                    base_func=eval(config.model.base_func),\n",
    "                    base_weights=config.model.base_weights\n",
    "                )\n",
    "                if stage_idx > 0:\n",
    "                    train_model.load_weights(os.path.join(config.save_path, f'latest-{fold_idx}.h5'))\n",
    "\n",
    "                val_model = build_model(\n",
    "                    tuple(config.transform.val_size) + (3,), config.num_classes, weight_decay=config.loss.weight_decay,\n",
    "                    dropout_rate=config.model.dropout_rate,\n",
    "                    base_func=eval(config.model.base_func),\n",
    "                    base_weights=config.model.base_weights\n",
    "                )\n",
    "\n",
    "        if e == 0:\n",
    "            csv_logger = mlc.LinewiseCSVWriter(\n",
    "                os.path.join(config.save_path, f'log-{fold_idx}.csv'),\n",
    "                header=['epoch'] + [f'train_{h}' for h in train_metrics.header] + [f'val_{h}' for h in val_metrics.header]\n",
    "            )\n",
    "            timer = mlc.time.Timer()\n",
    "            logger.info(f'fold-{fold_idx} start')\n",
    "\n",
    "\n",
    "        '''\n",
    "        train\n",
    "        '''\n",
    "        timer.add('train')\n",
    "        train_metrics, train_model, optimizer = proc_on_epoch(\n",
    "            True, train_on_batch, train_ds, train_metrics, criterion, train_model, e, config.num_epochs, \n",
    "            iters_per_epoch=train_iters_per_epoch, optimizer=optimizer\n",
    "        )\n",
    "        train_elapsed = timer.fsince('train')\n",
    "\n",
    "\n",
    "        '''\n",
    "        val\n",
    "        '''\n",
    "        val_model.set_weights(train_model.get_weights())\n",
    "        timer.add('val')\n",
    "        val_metrics = proc_on_epoch(\n",
    "            False, val_on_batch, val_ds, val_metrics, criterion, val_model, e, config.num_epochs, \n",
    "        )\n",
    "        val_elapsed = timer.fsince('val')\n",
    "\n",
    "\n",
    "        '''\n",
    "        log\n",
    "        '''\n",
    "        logger.info(f'epoch: {e+1} train: {train_elapsed} val: {val_elapsed}')\n",
    "        logger.info(f'train: {train_metrics.get_latest()[1]}')\n",
    "        logger.info(f'val: {val_metrics.get_latest()[1]}')\n",
    "        csv_logger.write([e+1] + train_metrics.get_latest()[1] + val_metrics.get_latest()[1])\n",
    "\n",
    "\n",
    "        '''\n",
    "        save\n",
    "        '''\n",
    "        val_model.save(os.path.join(config.save_path, f'latest-{fold_idx}.h5'))\n",
    "\n",
    "        val_loss = val_metrics.get_loss()\n",
    "        if val_loss < best_loss:\n",
    "            logger.info(f'loss got improved: {best_loss:.4f} to {val_loss:.4f}')\n",
    "            best_loss = val_loss\n",
    "            val_model.save(os.path.join(config.save_path, f'best_loss-{fold_idx}.h5'))\n",
    "\n",
    "        val_score = val_metrics.get_scores()[0]\n",
    "        if val_score > best_score:\n",
    "            logger.info(f'score got improved: {best_score:.4f} to {val_score:.4f}')\n",
    "            best_score = val_score\n",
    "            val_model.save(os.path.join(config.save_path, f'best_score-{fold_idx}.h5'))\n",
    "            \n",
    "            \n",
    "        '''\n",
    "        lr update\n",
    "        '''\n",
    "        curr_lr = optimizer.learning_rate.numpy()\n",
    "        next_lr = scheduler.get_next_lr(e+1, val_loss, val_score)\n",
    "        optimizer.learning_rate = next_lr\n",
    "        if curr_lr != next_lr:\n",
    "            logger.info(f'    lr {curr_lr} -> {next_lr}')\n",
    "    \n",
    "    \n",
    "    logger.info(f'fold-{fold_idx} end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-appearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config):\n",
    "    os.makedirs(config.save_path, exist_ok=True)\n",
    "    logger.add(os.path.join(config.save_path, 'log.txt'), mode='w')\n",
    "    OmegaConf.save(config, os.path.join(config.save_path, f'{config.expr_name}.yaml'))\n",
    "\n",
    "    for fold_idx in range(config.num_folds):\n",
    "        run_fold(fold_idx, config)\n",
    "\n",
    "        if config.run_fold1_only:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-resolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-kelly",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
